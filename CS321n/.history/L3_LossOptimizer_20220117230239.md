# Loss and Optimizer

## Outline

1. Loss Function
2. 
3. 


## Loss Function

    Loss Funtion is designed to measure the unaccuracy of the Classifier.

    "To quantify how bad are different mistakes"

## Loss Calculating Algorithm

General Format:$$Loss = \Sigma Loss_{i}(f(input;Weight);fact)$$

- SVM: 
$$Loss = \Sigma_{i \neq j} \max\{0, s_i - s_j + 1\}$$       

  note: $ i \neq j$ is necessary, or the Loss for a perfect answer is result in 1 not 0.

- Regularization(惩罚) Term: to pick a simpler $\mathbb{W}$
    $$Loss = \Sigma Loss_{i}(f(input;Weight);fact)+ \lambda \mathbb{R(Weight)}$$

    $\lambda$ called regularization strengh,is a hyporparameter to balance the two terms.

        Occam's Razor:"Among competing hypotheses, the simplest is the best."

Common use:
    - L2 regularization : $R(W) = \Sigma_i \Sigma_j W^{2}_{i,j}$
        ''Average the Weight!''
    - L1 regularization : $R(W) = \Sigma_i \Sigma_j |W_{i,j}|$ 
        "More zeros in Weight!"
    - Elastic net(L1+L2) : $R(W) = \Sigma_i \Sigma_j \beta|W_i,j|+W^{2}_{i,j}$ 
    - Max Norm Regularization
    - Dropout 

- SoftMax Loss

